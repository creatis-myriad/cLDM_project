net:
  lr: 2e-5
  num_timesteps: 1000
  scheduler: linear_beta
  scale_factor: 1.0

path_model_LDM: ${nn_dir}training_Pytorch/training_LDM/training_project_MICCAI_v2/2024-12-12 14:39:21_5000e_lightModel/
path_model_cond: ${nn_dir}training_Pytorch/training_AE_KL/training_LgeMyoSeg_v2/2024-12-17 17:42:50_autoencoder_for_seg_data/
path_model_autoencoder: ${nn_dir}training_Pytorch/training_AE_KL/training_LgeMyoSeg_v2/2024-12-05 11:44:11_base/


device: cuda
seed: 42

train_params:
  callback:
    monitor: train_loss

  batch_size: 32
  num_workers: 11
  persistent_workers: True
  split_test: 0.1
  split_val: 0.05
  shuffle: True
  min_epoch: 1
  max_epoch: 2